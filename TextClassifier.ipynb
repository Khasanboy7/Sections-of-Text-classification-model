{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TextClassifier.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1wOmwXOj-CVmZs-MmjdeCByqnmnfCOXEr","authorship_tag":"ABX9TyOJW2c4Q48U1ZbTZohSU+vQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hHFVRqOzFYrD"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import json"]},{"cell_type":"code","source":["import pathlib\n","path_to_file= pathlib.Path().parent/'rus.json'"],"metadata":{"id":"9EceOgkGx5uq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data(path):\n","    \n","    text = path.read_text(encoding='utf-8')\n","\n","    lines = text.splitlines()\n","    \n","    return lines"],"metadata":{"id":"hZ92Y-Fqx8up"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences=load_data(path_to_file)"],"metadata":{"id":"JAyrnpRoyFcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","\n","sequences = tokenizer.texts_to_sequences(sentences)\n","padded = pad_sequences(sequences, padding = 'post')\n","\n","print(padded[67])\n","print(padded.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0G-tCS_LzJcR","executionInfo":{"status":"ok","timestamp":1648115621858,"user_tz":-300,"elapsed":12545,"user":{"displayName":"Khasanboy Khasanboev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07003751309844415157"}},"outputId":"86e94b74-0a24-4bd2-d8b0-0b969024631a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0]\n","(438015, 81)\n"]}]},{"cell_type":"code","source":["training_sentences = sentences[0:2000]\n","testing_sentences = sentences[2000:]"],"metadata":{"id":"u0TdwO8E1zEQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences[3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"l85ZRm2pyNYa","executionInfo":{"status":"ok","timestamp":1648117825835,"user_tz":-300,"elapsed":249,"user":{"displayName":"Khasanboy Khasanboev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07003751309844415157"}},"outputId":"19cb6fb7-e253-44df-a376-5b05e50d7619"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Здравствуйте.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["print(padded[0])\n","print(padded.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4Ma7vKDj2r0","executionInfo":{"status":"ok","timestamp":1648117827989,"user_tz":-300,"elapsed":255,"user":{"displayName":"Khasanboy Khasanboev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07003751309844415157"}},"outputId":"c4a207de-0fa0-40a1-8f16-9ee0a6d73287"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0]\n","(438015, 81)\n"]}]},{"cell_type":"code","source":["predictions = tf.argmax(sequences, axis = None)\n","predictions = [tokenizer.decode(pred) for pred in predictions.numpy().tolist()]  \n","print(predictions)"],"metadata":{"id":"ORbIvNt5GvHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(training_sentences)\n","\n","word_index = tokenizer.word_index\n","\n","training_sequences = tokenizer.texts_to_sequences(training_sentences)\n","training_padded = pad_sequences(training_sequences, maxlen = max_length)"],"metadata":{"id":"lRA_GQDYBaX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testing_sequences = tokenizer.texts_to_sequences(training_sentences)\n"],"metadata":{"id":"CrXgqqxEexr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import List\n","import numpy as np\n","import nltk\n","from itertools import chain\n","nltk.download('punkt')\n","\n","def create_dataset(texts: List[str], min_sentence_length_for_splitting=10):\n","    '''\n","    Create positives and negatives pairs of sentences.\n","    Positive pair is a pair of sentences that should be splitted, using nltk.sent_tokenize (without \\n).\n","    Negative pair is a sentence that we split in the middle\n","    '''\n","    positives_pairs = []\n","    negative_pairs = []\n","    for text in texts:\n","        sentences = nltk.sent_tokenize(text)\n","        if len(sentences)>1:\n","          sentences = [nltk.tokenize.word_tokenize(sentence.replace('.', '')) for sentence in sentences]\n","          sentences_pairs = list(zip(sentences[:-1], sentences[1:]))\n","          positives_pairs.append(sentences_pairs)\n","\n","          for negative_sample in sentences:  # split sentence in the middle\n","              if len(negative_sample) > min_sentence_length_for_splitting:\n","                  first_sent, second_sent = negative_sample[:len(negative_sample) // 2], negative_sample[\n","                                                                                          len(negative_sample) // 2:]\n","                  negative_pairs.append([(first_sent, second_sent)])\n","    \n","    positives_pairs = list(chain.from_iterable(positives_pairs))\n","    negative_pairs = list(chain.from_iterable(negative_pairs))\n","    \n","    return positives_pairs, negative_pairs\n","   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxSjdfH0rxkf","executionInfo":{"status":"ok","timestamp":1648125964116,"user_tz":-300,"elapsed":562,"user":{"displayName":"Khasanboy Khasanboev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07003751309844415157"}},"outputId":"991c3d4c-2aa8-4f45-f69e-63c2b6a51370"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"rOiGoYqJSoXo"},"execution_count":null,"outputs":[]}]}